{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#The point of this code is to parse through the Bay Area Dataset line by line by converting each row to an ordered dictionary.\n",
    "#In each iteration, the dictionary is processed to remove unnecessary columns, and if the company name in the dictionary corresponds\n",
    "#with a company on the warn top 30 companies dataset, I append the dictionary to a final merged dataframe containing warn\n",
    "#and bay_area columns.\n",
    "\n",
    "#EDIT: This script has been modified to generate a dataframe with profiles that work in the top 30 commpanies and were not\n",
    "#laid off\n",
    "\n",
    "# TODO: Parse top 30 names and convert to list\n",
    "warn=pd.read_csv(r\"C:\\Ran\\Berkeley\\IEOR\\290\\EmploymentDynamics\\ImportantCSVs\\top30.csv\")\n",
    "top30_company_names=warn['Company Name'].tolist()\n",
    "top30_company_tickers = warn['Ticker'].tolist()\n",
    "\n",
    "warn_matched_companies=[] #intermediate variable used to store rows of the warn dataset that match with the bay area company names\n",
    "final_merged_dictionary=dict() #Dictionary used to store merged bay_area and warn dictionaries\n",
    "final_merged_dataframe=pd.DataFrame() #Converting each row of merged dictionary and appending it to this dataframe\n",
    "final_merged_dictionary2 =dict() #Dictionary used to store merged bay_area and warn dictionaries\n",
    "final_merged_dataframe2 = pd.DataFrame() #Converting each row of merged dictionary and appending it to this dataframe\n",
    "\n",
    "\n",
    "with open(r\"..\\Project\\Data\\bay_area.csv\", encoding='utf-8') as csvfile:\n",
    "    colnames=['ID', 'Birth Year', 'Gender Flag', 'Skillset1', 'Skillset1 Weight', 'Skillset2', 'Skillset2 Weight', 'City of profile','Country of profile','Education','Elite Institution', 'Start Date', 'StartFlag','End Date', 'EndFlag', 'CurrentEmployFlag','Length','Role','Dept','Company','Company_Norm','Ticker','Exchange','PublicFlag','Location','Industry','EducationFlag','DegreeType','EliteFlag','Dummy1','Dummy2','Dummy3','Dummy4']\n",
    "    reader = csv.DictReader(csvfile, delimiter='\\t', fieldnames=colnames)\n",
    "    count=0;\n",
    "\n",
    "    for idx, row in enumerate(reader):\n",
    "        if idx % 100000 == 0:\n",
    "            print(idx)\n",
    "        #change idx condition to only process the number of rows you want.\n",
    "        #if idx >= 5000000:\n",
    "            #break\n",
    "        #If skillset columns are empty, or if end date is not listed, added\n",
    "        if row['Skillset1'] == \"-1\" or row['Skillset2'] == \"-1\" or row['End Date']=='None':\n",
    "            continue\n",
    "        elif row['Company'] in top30_company_names or row['Ticker'] in top30_company_tickers:\n",
    "            indices = [i for i, (x, y) in enumerate(zip(top30_company_names, top30_company_tickers)) if x == row['Company'] or y == row['Ticker']]  \n",
    "            \n",
    "            \n",
    "            warn_matched_companies=warn.iloc[indices]\n",
    "            for index,rowwarn in warn_matched_companies.iterrows():\n",
    "                bay_area_end_date=pd.to_datetime(row['End Date'],infer_datetime_format=True)\n",
    "                layoff_date=pd.to_datetime(rowwarn['Layoff Date'],infer_datetime_format=True)\n",
    "                if ((abs(bay_area_end_date-layoff_date) / np.timedelta64(1,'M')) > 6): #Only appending rows \n",
    "                    #if layoff and end dates are outside 6 months of each other (leaving not because of layoff)\n",
    "                    \n",
    "                    #Converting warn data to a dictionary\n",
    "                    warn_dict=dict()\n",
    "                    warn_dict.update({'Layoff Date':rowwarn['Layoff Date']})\n",
    "                    warn_dict.update({'Company Name':rowwarn['Company Name']})\n",
    "                    warn_dict.update({'Employees Affected':rowwarn['Employees Affected']})\n",
    "                    #merging the warn and bay area dictionaries.\n",
    "                    final_merged_dictionary.update(row)\n",
    "                    final_merged_dictionary.update(warn_dict)\n",
    "                    final_merged_dataframe=final_merged_dataframe.append(pd.DataFrame(final_merged_dictionary,columns=final_merged_dictionary.keys(),index=[0]))\n",
    "                    count=count+1;\n",
    "                    \n",
    "                elif ((abs(bay_area_end_date-layoff_date) / np.timedelta64(1,'M')) < 1): #Only appending rows \n",
    "                    #if layoff and end dates are within 1 month of each other (leaving because of layoff)\n",
    "                    \n",
    "                    #Converting warn data to a dictionary\n",
    "                    warn_dict2=dict()\n",
    "                    warn_dict2.update({'Layoff Date':rowwarn['Layoff Date']})\n",
    "                    warn_dict2.update({'Company Name':rowwarn['Company Name']})\n",
    "                    warn_dict2.update({'Employees Affected':rowwarn['Employees Affected']})\n",
    "                    #merging the warn and bay area dictionaries.\n",
    "                    final_merged_dictionary2.update(row)\n",
    "                    final_merged_dictionary2.update(warn_dict2)\n",
    "                    final_merged_dataframe2 = final_merged_dataframe2.append(pd.DataFrame(final_merged_dictionary2,columns=final_merged_dictionary2.keys(),index=[0]))\n",
    "                    count=count+1;   \n",
    "            \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_dataframe['laid_off'] = 0 #classify as \"Not laid-off\" \n",
    "#because the difference between \"End- date\" and \"Layoff- Date\" exceed 6 mo\n",
    "final_merged_dataframe2['laid_off'] = 1 #classify as \"laid-off\" \n",
    "#because the difference between \"End- date\" and \"Layoff- Date\" is within 1 mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData = pd.concat([final_merged_dataframe, final_merged_dataframe2])\n",
    "#trainingData.to_csv(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
